[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/T6T41IT163)

# ðŸ° Ad Arbitorium (Datacenter) â€” Private GitOps Repository

> _"When the cluster's down, and the world is on fire, at least you can still run Ansible."_ ðŸ”¥

Welcome to the heart of Ad Arbitorium; a GitOps repository describing the active configuration of our homelab/datacenter. This repo aims to be the source of truth for system state, automation routines, and backup strategies.


---

> Maintained by [SoFMeRight](https://github.com/sofmeright) for [PrPlanIT](https://prplanit.com) â€” Real world results for your real world expectations.

---

## ðŸ“‚ Repository Layout

This repository contains:
> (a simple directory structure)
- ðŸ§ª **Ansible Playbooks**: Stored in the `ansible/*/` directory
- ðŸ§ **Inventory Definitions**: Locate at `ansible/inventory`
- ðŸ“¦ **Docker Compose Deployments** Stored in the `docker-compose` directory
- ðŸ•¸ï¸ **NGINX Proxy Configurations** Stored in the `nginx-extras` directory
- âš™ï¸ **General Configuration Files** Stored in the `fs` directory
- ðŸ’« **FluxCD Configuration** Located at the `fluxcd` directory
- ðŸ’¾ **Backup Automation & Recovery Scripts**

Where possible, configuration is version-controlled. In some cases (e.g., Docker volumes or secrets), data resides in protected resources or local mounts.

---

## âš™ï¸ Automations & Tooling

### ðŸ› ï¸ Primary Automation: Ansible

We use [Ansible](https://www.ansible.com/) with playbooks stored in this repo and executed via:

- ðŸ” [Ansible Semaphore](https://ansible-semaphore.com/) â€” for web-based job triggering
- ðŸ³ GitLab CI/CD Components â€” for automated GitOps-style deployments
- ðŸ’¡ *Ideas in progress*: OliveTin, or Cronguru for task selection. Docker deployment script in progress, plannint to use SOPs to encrypt docker secrets inline.

### ðŸ—„ï¸ Repository Recovery

> **ant-parade & leaf-cutter** to the rescue! ðŸœ

If the cluster fails, we can recover from a local repo clone on `leaf-cutter`:

```bash
docker run --rm \
  -v /srv/gitops/ad-arbitorium-private:/srv/gitops/ad-arbitorium-private \
  -v ~/.ssh/id_rsa:/root/.ssh/id_rsa \
  cr.pcfae.com/prplanit/ansible:2.18.6 \
  ansible-playbook --private-key /root/.ssh/id_rsa \
  -i /srv/gitops/ad-arbitorium-private/ansible/inventory \
  /srv/gitops/ad-arbitorium-private/ansible/infrastructure/qemu-guest-agent-debian.yaml
```
##### WinRM Example:
```
docker run -v ./playbook.yaml:/root/playbook.yaml -v /srv/gitops/ad-arbitorium-private:/srv/gitops/ad-arbitorium-private -v ~/.ssh/id_rsa:/root/.ssh/id_rsa --rm cr.pcfae.com/prplanit/ansible:2.18.6 ansible-playbook --private-key /root/.ssh/id_rsa -i /srv/gitops/ad-arbitorium-private/ansible/inventory /root/playbook.yaml -e ansible_windows_password=$WINDOWS_ANSIBLE_PASSWORD
```

## ðŸ“… Backup Schedule

Our peak hours are typically 6:00AM â€“ 10:00PM PST. Backups are scheduled to minimize risk during these times.

| Day           | Time  | Task                                             |
| ------------- | ----- | ------------------------------------------------ |
| Mon, Fri      | 22:00 | NAS & PBS â†’ local-zfs backup                     |
| Tue, Thu, Fri | 23:00 | All other core/essential VMs â†’ Flashy-Fuscia-SSD |

## ðŸ–¥ï¸ Hardware Overview

The datacenter is powered by Proxmox VE and consists of five clustered nodes:

| Host           | CPU                                     | RAM                |
| -------------- | --------------------------------------- | ------------------ |
| ðŸ¥‘ Avocado     | 2Ã— Xeon E5-2680 v3 (24C/48T) 2.5â€“3.3GHz | 256GB (8Ã—32GB ECC) |
| ðŸŽ Bamboo      | 2Ã— Xeon E5-2680 v4 (28C/56T) 2.4â€“3.3GHz | 96GB (6Ã—16GB ECC)  |
| ðŸŒŒ Cosmos      | 2Ã— Xeon E5-2667 v3 (16C/32T) 3.2â€“3.6GHz | 256GB (8Ã—32GB ECC) |
| ðŸ‰ Dragonfruit | AMD Ryzen 7 2700X (8C/16T) 3.7â€“4.35GHz  | 64GB (2Ã—32GB ECC)  |
| ðŸ† Eggplant    | 2Ã— Xeon E5-2683 v3 (28C/56T) 2.0â€“3.0GHz | 128GB (16Ã—8GB ECC) |

#### ðŸª² leaf-cutter (Unclustered automation node)
- CPU: Intel i7-4720HQ (8 threads @ 3.6GHz)
- RAM: 16GB (2Ã—8GB DDR3)
- This node runs critical automation if the cluster fails. Think of it as "ant-parade's stunt double."

## ðŸ§  Observability & Monitoring
- Grafana + Loki + Prometheus for metrics & logs
- Crowdsec for IDS/IPS and pfsense integration
- Beszel alternative option for metrics
- Wazuh
- Portainer for container management dashboards

## ðŸŒ Networking Overview

##### Firewall / Routing: 
- Dual HA/CARP pfSense VMs on Avocado & Bamboo

##### Networking:

- OSPFv6 for internal Proxmox/Ceph
- BGP for Kubernetes w/ metallb
- HAProxy load balancing for K8s API
- DNS: Highly available AdGuardHome DNS pair with sync

##### Reverse Proxies:

- cell-membrane, phloem, and xylem handle NGINX proxy duties
> Internal domains like *.pcfae.com live inside xylem (no external exposure)

## ðŸ“ž Remote Access Tools
- rustdesk, moonlight, sunshine, tactical-rmm

## ðŸ§± Core Workloads
- PVE â€“ Bare metal Proxmox hosts
- Ubuntu 24.04 + Docker â€“ Most VMs run containers (including GPU workloads)
- pfSense â€“ Dual-stack IPv4/6 (future: evaluate opnSense again)
- FusionPBX â€“ VOIP System
- Home Assistant OS
- Kubernetes â€“ 5-node cluster, likely reducing to 3 masters soon
- PBS (Proxmox Backup Server)
- Portainer â€“ Jump node: harbormaster
- Shinobi â€“ CCTV & surveillance
- TrueNAS
- Windows Server â€“ Active Directory 3-node forest

## ðŸ”’ VPN / Remote Access

- netbird

## ðŸ“¦ Docker Stacks:

> A full table should be populated with deployments when the pipeline runs and it will be linked to this segment in the near, near future. 

> In the meantime all deployments can be reviewed within the repository.

## ðŸ¤“ Want to contribute or improve the stack?
This is a private lab, but feedback, discussion, and memes are always welcome. âœ‰ï¸

## âš ï¸ Disclaimer

> The code, images, and infrastructure templates herein (the "Software") are provided as-is and as-absurdâ€”without warranties, guarantees, or even friendly nudges. The authors accept no liability if this repo makes your cluster self-aware, breaks your ankle (metaphorically or otherwise), or causes irreversible YAML-induced burnout.

We take no responsibility if running this setup somehow:

- launches a container into orbit,

- bricks your homelab,

- or awakens a long-dormant AI from /dev/null.

> Use at your own risk. If it works, thank the open-source gods. If it doesn't, well... you probably learned something.
